{"ast":null,"code":"var _jsxFileName = \"/Users/piyushprashant/Documents/funproject/mood-detector/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState, useRef } from \"react\";\nimport * as faceApi from \"face-api.js\";\nimport './App.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const [initializing, setInitializing] = useState(false);\n  const videoRef = useRef();\n  const canvasRef = useRef();\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([faceApi.nets.tinyFaceDetector.loadFromUri(MODEL_URL), faceApi.nets.faceLandmark68Net.loadFromUri(MODEL_URL), faceApi.nets.faceRecognitionNet.loadFromUri(MODEL_URL), faceApi.nets.faceExpressionNet.loadFromUri(MODEL_URL), faceApi.nets.ageGenderNet.loadFromUri(MODEL_URL)]).then(() => startVideo());\n    };\n\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    window.navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n    window.navigator.getUserMedia({\n      video: true,\n      audio: false\n    }, stream => {\n      return videoRef.current.srcObject = stream;\n    }, err => console.log(err));\n  };\n\n  const handleVideoPlay = () => {\n    canvasRef.current.innerHTML = faceApi.createCanvasFromMedia(videoRef.current);\n    const displaySize = {\n      width: videoWidth,\n      height: videoHeight\n    };\n    faceApi.matchDimensions(canvasRef.current, displaySize);\n\n    if (initializing) {\n      setInitializing(false);\n    }\n\n    setInterval(async () => {\n      const detections = await faceApi.detectAllFaces(videoRef.current, new faceApi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions().withAgeAndGender();\n      const resizedDetections = faceApi.resizeResults(detections, displaySize);\n      console.log(resizedDetections);\n      canvasRef.current.getContext(\"2d\").clearRect(0, 0, videoWidth, videoWidth);\n      faceApi.draw.drawDetections(canvasRef.current, resizedDetections);\n      faceApi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n      faceApi.draw.drawFaceExpressions(canvasRef.current, resizedDetections);\n      resizedDetections.forEach(detection => {\n        const box = detection.detection.box;\n        const drawBox = new faceApi.draw.DrawBox(box, {\n          label: Math.round(detection.age) + \" year old \" + detection.gender\n        });\n        drawBox.draw(canvasRef.current);\n      });\n    }, 100); // clearInterval(interval)\n  }; // \n  // faceApi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections)\n  // faceApi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      children: initializing ? \"Initializing\" : \"Ready\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 5\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"flex justify-center\",\n      children: [/*#__PURE__*/_jsxDEV(\"video\", {\n        ref: videoRef,\n        autoPlay: true,\n        muted: true,\n        height: videoHeight,\n        width: videoWidth,\n        onPlay: handleVideoPlay\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 77,\n        columnNumber: 7\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        className: \"position-absolute\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 85,\n        columnNumber: 7\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 76,\n      columnNumber: 5\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 72,\n    columnNumber: 3\n  }, this);\n}\n\n_s(App, \"Xg6yX5IqQ2Gk/jClXeKvvsq5YQk=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/piyushprashant/Documents/funproject/mood-detector/src/App.js"],"names":["React","useEffect","useState","useRef","faceApi","App","videoHeight","videoWidth","initializing","setInitializing","videoRef","canvasRef","loadModels","MODEL_URL","process","env","PUBLIC_URL","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","startVideo","window","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","video","audio","stream","current","srcObject","err","console","log","handleVideoPlay","innerHTML","createCanvasFromMedia","displaySize","width","height","matchDimensions","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","withAgeAndGender","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions","forEach","detection","box","drawBox","DrawBox","label","Math","round","age","gender"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,QAA3B,EAAqCC,MAArC,QAAmD,OAAnD;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;AACA,OAAO,WAAP;;;AAIA,SAASC,GAAT,GAAe;AAAA;;AACb,QAAMC,WAAW,GAAG,GAApB;AACA,QAAMC,UAAU,GAAG,GAAnB;AACA,QAAM,CAACC,YAAD,EAAeC,eAAf,IAAkCP,QAAQ,CAAC,KAAD,CAAhD;AACA,QAAMQ,QAAQ,GAAGP,MAAM,EAAvB;AACA,QAAMQ,SAAS,GAAGR,MAAM,EAAxB;AACAF,EAAAA,SAAS,CAAC,MAAM;AACd,UAAMW,UAAU,GAAG,YAAY;AAC7B,YAAMC,SAAS,GAAGC,OAAO,CAACC,GAAR,CAAYC,UAAZ,GAAyB,SAA3C;AACAP,MAAAA,eAAe,CAAC,IAAD,CAAf;AACAQ,MAAAA,OAAO,CAACC,GAAR,CAAY,CACVd,OAAO,CAACe,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0CR,SAA1C,CADU,EAEVT,OAAO,CAACe,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2CR,SAA3C,CAFU,EAGVT,OAAO,CAACe,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4CR,SAA5C,CAHU,EAIVT,OAAO,CAACe,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2CR,SAA3C,CAJU,EAKVT,OAAO,CAACe,IAAR,CAAaM,YAAb,CAA0BJ,WAA1B,CAAsCR,SAAtC,CALU,CAAZ,EAMGa,IANH,CAMQ,MAAMC,UAAU,EANxB;AAOD,KAVD;;AAWAf,IAAAA,UAAU;AACX,GAbQ,EAaN,EAbM,CAAT;;AAcA,QAAMe,UAAU,GAAG,MAAM;AACvBC,IAAAA,MAAM,CAACC,SAAP,CAAiBC,YAAjB,GAAiCD,SAAS,CAACC,YAAV,IAA0BD,SAAS,CAACE,kBAApC,IAA0DF,SAAS,CAACG,eAApE,IAAuFH,SAAS,CAACI,cAAlI;AACAL,IAAAA,MAAM,CAACC,SAAP,CAAiBC,YAAjB,CAA8B;AAAEI,MAAAA,KAAK,EAAE,IAAT;AAC5BC,MAAAA,KAAK,EAAE;AADqB,KAA9B,EAEGC,MAAM,IAAI;AAEX,aAAO1B,QAAQ,CAAC2B,OAAT,CAAiBC,SAAjB,GAA6BF,MAApC;AACD,KALD,EAKGG,GAAG,IAAIC,OAAO,CAACC,GAAR,CAAYF,GAAZ,CALV;AAMD,GARD;;AASA,QAAMG,eAAe,GAAG,MAAM;AAC5B/B,IAAAA,SAAS,CAAC0B,OAAV,CAAkBM,SAAlB,GAA8BvC,OAAO,CAACwC,qBAAR,CAA8BlC,QAAQ,CAAC2B,OAAvC,CAA9B;AACA,UAAMQ,WAAW,GAAG;AAAEC,MAAAA,KAAK,EAAEvC,UAAT;AAAqBwC,MAAAA,MAAM,EAAEzC;AAA7B,KAApB;AACAF,IAAAA,OAAO,CAAC4C,eAAR,CAAwBrC,SAAS,CAAC0B,OAAlC,EAA2CQ,WAA3C;;AACA,QAAIrC,YAAJ,EAAkB;AAChBC,MAAAA,eAAe,CAAC,KAAD,CAAf;AACD;;AACAwC,IAAAA,WAAW,CAAC,YAAY;AACvB,YAAMC,UAAU,GAAG,MAAM9C,OAAO,CAC7B+C,cADsB,CACPzC,QAAQ,CAAC2B,OADF,EACW,IAAIjC,OAAO,CAACgD,uBAAZ,EADX,EAEtBC,iBAFsB,GAGtBC,mBAHsB,GAItBC,gBAJsB,EAAzB;AAMA,YAAMC,iBAAiB,GAAGpD,OAAO,CAACqD,aAAR,CAAsBP,UAAtB,EAAkCL,WAAlC,CAA1B;AACAL,MAAAA,OAAO,CAACC,GAAR,CAAYe,iBAAZ;AACA7C,MAAAA,SAAS,CAAC0B,OAAV,CAAkBqB,UAAlB,CAA6B,IAA7B,EAAmCC,SAAnC,CAA6C,CAA7C,EAAgD,CAAhD,EAAmDpD,UAAnD,EAA+DA,UAA/D;AACAH,MAAAA,OAAO,CAACwD,IAAR,CAAaC,cAAb,CAA4BlD,SAAS,CAAC0B,OAAtC,EAA+CmB,iBAA/C;AACApD,MAAAA,OAAO,CAACwD,IAAR,CAAaE,iBAAb,CAA+BnD,SAAS,CAAC0B,OAAzC,EAAkDmB,iBAAlD;AACApD,MAAAA,OAAO,CAACwD,IAAR,CAAaG,mBAAb,CAAiCpD,SAAS,CAAC0B,OAA3C,EAAoDmB,iBAApD;AACAA,MAAAA,iBAAiB,CAACQ,OAAlB,CAA2BC,SAAS,IAAI;AACtC,cAAMC,GAAG,GAAGD,SAAS,CAACA,SAAV,CAAoBC,GAAhC;AACA,cAAMC,OAAO,GAAG,IAAI/D,OAAO,CAACwD,IAAR,CAAaQ,OAAjB,CAAyBF,GAAzB,EAA8B;AAAEG,UAAAA,KAAK,EAAEC,IAAI,CAACC,KAAL,CAAWN,SAAS,CAACO,GAArB,IAA4B,YAA5B,GAA2CP,SAAS,CAACQ;AAA9D,SAA9B,CAAhB;AACAN,QAAAA,OAAO,CAACP,IAAR,CAAajD,SAAS,CAAC0B,OAAvB;AACD,OAJD;AAOD,KApBW,EAoBT,GApBS,CAAX,CAP2B,CA4B5B;AACD,GA7BD,CA7Ba,CA4Db;AACA;AACA;;;AAEF,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BACE;AAAA,gBACG7B,YAAY,GAAG,cAAH,GAAoB;AADnC;AAAA;AAAA;AAAA;AAAA,YADF,eAIE;AAAK,MAAA,SAAS,EAAE,qBAAhB;AAAA,8BACE;AACE,QAAA,GAAG,EAAEE,QADP;AAEE,QAAA,QAAQ,MAFV;AAGE,QAAA,KAAK,MAHP;AAIE,QAAA,MAAM,EAAEJ,WAJV;AAKE,QAAA,KAAK,EAAEC,UALT;AAME,QAAA,MAAM,EAAEmC;AANV;AAAA;AAAA;AAAA;AAAA,cADF,eASE;AAAQ,QAAA,GAAG,EAAE/B,SAAb;AAAwB,QAAA,SAAS,EAAC;AAAlC;AAAA;AAAA;AAAA;AAAA,cATF;AAAA;AAAA;AAAA;AAAA;AAAA,YAJF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAmBC;;GAnFQN,G;;KAAAA,G;AAqFT,eAAeA,GAAf","sourcesContent":["import React, { useEffect, useState, useRef } from \"react\"\nimport * as faceApi from \"face-api.js\"\nimport './App.css';\n\n\n\nfunction App() {\n  const videoHeight = 480\n  const videoWidth = 640\n  const [initializing, setInitializing] = useState(false)\n  const videoRef = useRef()\n  const canvasRef = useRef()\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models'\n      setInitializing(true)\n      Promise.all([\n        faceApi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceApi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceApi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceApi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceApi.nets.ageGenderNet.loadFromUri(MODEL_URL)\n      ]).then(() => startVideo())\n    }\n    loadModels()\n  }, [])\n  const startVideo = () => {\n    window.navigator.getUserMedia = (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia)\n    window.navigator.getUserMedia({ video: true,\n      audio: false\n    }, stream => {\n\n      return videoRef.current.srcObject = stream\n    }, err => console.log(err))\n  }\n  const handleVideoPlay = () => {\n    canvasRef.current.innerHTML = faceApi.createCanvasFromMedia(videoRef.current);\n    const displaySize = { width: videoWidth, height: videoHeight};\n    faceApi.matchDimensions(canvasRef.current, displaySize);\n    if (initializing) {\n      setInitializing(false)\n    }\n     setInterval(async () => {\n      const detections = await faceApi\n        .detectAllFaces(videoRef.current, new faceApi.TinyFaceDetectorOptions())\n        .withFaceLandmarks()\n        .withFaceExpressions()\n        .withAgeAndGender()\n        ;\n      const resizedDetections = faceApi.resizeResults(detections, displaySize);\n      console.log(resizedDetections)\n      canvasRef.current.getContext(\"2d\").clearRect(0, 0, videoWidth, videoWidth);\n      faceApi.draw.drawDetections(canvasRef.current, resizedDetections)\n      faceApi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections)\n      faceApi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n      resizedDetections.forEach( detection => {\n        const box = detection.detection.box\n        const drawBox = new faceApi.draw.DrawBox(box, { label: Math.round(detection.age) + \" year old \" + detection.gender })\n        drawBox.draw(canvasRef.current)\n      })\n      \n   \n    }, 100);\n    // clearInterval(interval)\n  }\n\n  // \n  // faceApi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections)\n  // faceApi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n\nreturn (\n  <div className=\"App\">\n    <div>\n      {initializing ? \"Initializing\" : \"Ready\"}\n    </div>\n    <div className =\"flex justify-center\">\n      <video\n        ref={videoRef}\n        autoPlay\n        muted\n        height={videoHeight}\n        width={videoWidth}\n        onPlay={handleVideoPlay}\n      />\n      <canvas ref={canvasRef} className=\"position-absolute\" />\n    </div>\n\n  </div>\n);\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}