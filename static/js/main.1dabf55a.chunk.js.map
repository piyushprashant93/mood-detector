{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["App","videoWidth","useState","initializing","setInitializing","videoRef","useRef","canvasRef","useEffect","a","MODEL_URL","process","Promise","all","faceApi","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","startVideo","loadModels","window","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","video","audio","stream","current","srcObject","err","console","log","className","ref","autoPlay","muted","height","width","onPlay","innerHTML","displaySize","setInterval","withFaceLandmarks","withFaceExpressions","withAgeAndGender","detections","resizedDetections","getContext","clearRect","drawDetections","drawFaceLandmarks","drawFaceExpressions","forEach","detection","box","DrawBox","label","Math","round","age","gender","draw","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"8TA2FeA,MArFf,WACE,IACMC,EAAa,IACnB,EAAwCC,oBAAS,GAAjD,mBAAOC,EAAP,KAAqBC,EAArB,KACMC,EAAWC,mBACXC,EAAYD,mBAClBE,qBAAU,YACQ,uCAAG,4BAAAC,EAAA,sDACXC,EAAYC,wBAClBP,GAAgB,GAChBQ,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAAYN,GAC1CI,IAAaG,kBAAkBD,YAAYN,GAC3CI,IAAaI,mBAAmBF,YAAYN,GAC5CI,IAAaK,kBAAkBH,YAAYN,GAC3CI,IAAaM,aAAaJ,YAAYN,KACrCW,MAAK,kBAAMC,OATG,2CAAH,qDAWhBC,KACC,IACH,IAAMD,EAAa,WACjBE,OAAOC,UAAUC,aAAgBD,UAAUC,cAAgBD,UAAUE,oBAAsBF,UAAUG,iBAAmBH,UAAUI,eAClIL,OAAOC,UAAUC,aAAa,CAAEI,OAAO,EACrCC,OAAO,IACN,SAAAC,GAED,OAAO3B,EAAS4B,QAAQC,UAAYF,KACnC,SAAAG,GAAG,OAAIC,QAAQC,IAAIF,OAqC1B,OACE,sBAAKG,UAAU,MAAf,UACE,8BACGnC,EAAe,eAAiB,UAEnC,sBAAKmC,UAAW,sBAAhB,UACE,uBACEC,IAAKlC,EACLmC,UAAQ,EACRC,OAAK,EACLC,OAzEc,IA0EdC,MAAO1C,EACP2C,OA/CkB,WACtBrC,EAAU0B,QAAQY,UAAY/B,IAA8BT,EAAS4B,SACrE,IAAMa,EAAc,CAAEH,MAAO1C,EAAYyC,OA9BvB,KA+BlB5B,IAAwBP,EAAU0B,QAASa,GACvC3C,GACFC,GAAgB,GAEjB2C,YAAW,sBAAC,8BAAAtC,EAAA,sEACcK,IACPT,EAAS4B,QAAS,IAAInB,KACrCkC,oBACAC,sBACAC,mBALQ,OACLC,EADK,OAOLC,EAAoBtC,IAAsBqC,EAAYL,GAC5DV,QAAQC,IAAIe,GACZ7C,EAAU0B,QAAQoB,WAAW,MAAMC,UAAU,EAAG,EAAGrD,EAAYA,GAC/Da,IAAayC,eAAehD,EAAU0B,QAASmB,GAC/CtC,IAAa0C,kBAAkBjD,EAAU0B,QAASmB,GAClDtC,IAAa2C,oBAAoBlD,EAAU0B,QAASmB,GACpDA,EAAkBM,SAAS,SAAAC,GACzB,IAAMC,EAAMD,EAAUA,UAAUC,IAChB,IAAI9C,IAAa+C,QAAQD,EAAK,CAAEE,MAAOC,KAAKC,MAAML,EAAUM,KAAO,aAAeN,EAAUO,SACpGC,KAAK5D,EAAU0B,YAhBd,4CAoBV,QAsBD,wBAAQM,IAAKhC,EAAW+B,UAAU,6BCxEzB8B,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBjD,MAAK,YAAkD,IAA/CkD,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.1dabf55a.chunk.js","sourcesContent":["import React, { useEffect, useState, useRef } from \"react\"\nimport * as faceApi from \"face-api.js\"\nimport './App.css';\n\n\n\nfunction App() {\n  const videoHeight = 480\n  const videoWidth = 640\n  const [initializing, setInitializing] = useState(false)\n  const videoRef = useRef()\n  const canvasRef = useRef()\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models'\n      setInitializing(true)\n      Promise.all([\n        faceApi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceApi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceApi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceApi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceApi.nets.ageGenderNet.loadFromUri(MODEL_URL)\n      ]).then(() => startVideo())\n    }\n    loadModels()\n  }, [])\n  const startVideo = () => {\n    window.navigator.getUserMedia = (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia)\n    window.navigator.getUserMedia({ video: true,\n      audio: false\n    }, stream => {\n\n      return videoRef.current.srcObject = stream\n    }, err => console.log(err))\n  }\n  const handleVideoPlay = () => {\n    canvasRef.current.innerHTML = faceApi.createCanvasFromMedia(videoRef.current);\n    const displaySize = { width: videoWidth, height: videoHeight};\n    faceApi.matchDimensions(canvasRef.current, displaySize);\n    if (initializing) {\n      setInitializing(false)\n    }\n     setInterval(async () => {\n      const detections = await faceApi\n        .detectAllFaces(videoRef.current, new faceApi.TinyFaceDetectorOptions())\n        .withFaceLandmarks()\n        .withFaceExpressions()\n        .withAgeAndGender()\n        ;\n      const resizedDetections = faceApi.resizeResults(detections, displaySize);\n      console.log(resizedDetections)\n      canvasRef.current.getContext(\"2d\").clearRect(0, 0, videoWidth, videoWidth);\n      faceApi.draw.drawDetections(canvasRef.current, resizedDetections)\n      faceApi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections)\n      faceApi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n      resizedDetections.forEach( detection => {\n        const box = detection.detection.box\n        const drawBox = new faceApi.draw.DrawBox(box, { label: Math.round(detection.age) + \" year old \" + detection.gender })\n        drawBox.draw(canvasRef.current)\n      })\n      \n   \n    }, 100);\n    // clearInterval(interval)\n  }\n\n  // \n  // faceApi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections)\n  // faceApi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n\nreturn (\n  <div className=\"App\">\n    <div>\n      {initializing ? \"Initializing\" : \"Ready\"}\n    </div>\n    <div className =\"flex justify-center\">\n      <video\n        ref={videoRef}\n        autoPlay\n        muted\n        height={videoHeight}\n        width={videoWidth}\n        onPlay={handleVideoPlay}\n      />\n      <canvas ref={canvasRef} className=\"position-absolute\" />\n    </div>\n\n  </div>\n);\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}